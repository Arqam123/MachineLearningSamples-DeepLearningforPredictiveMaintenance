{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Model Operationalization & Deployment\n",
    "\n",
    "In the previous script, you learned how to save lstm trained models to files. You also learned that model weights are easily stored using  HDF5 format and that the network structure can be saved in JSON. In this script, you will learn how to load your models up, operationalize and use them to make future predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import keras\n",
    "import numpy as np\n",
    "# import the libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import urllib\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# Setting seed for reproducability\n",
    "np.random.seed(1234)  \n",
    "PYTHONHASHSEED = 0\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "from keras.models import Sequential\n",
    "#from keras.layers import Dense, Dropout, LSTM, Activation gdt\n",
    "\n",
    "import h5py\n",
    "from sklearn import datasets\n",
    "\n",
    "# Setup the pyspark environment\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "\n",
    "# Use the Azure Machine Learning data collector to log various metrics\n",
    "from azureml.logging import get_azureml_logger\n",
    "\n",
    "# For Azure blob storage access\n",
    "from azure.storage.blob import BlockBlobService\n",
    "from azure.storage.blob import PublicAccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azureml.logging.script_run_request.ScriptRunRequest at 0x7f8af2191278>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.logging import get_azureml_logger\n",
    "run_logger = get_azureml_logger()\n",
    "run_logger.log('amlrealworld.predictivemaintenanceforpm.operationalization','true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Azure blob storage details here \n",
    "ACCOUNT_NAME = \"<your blob storage account name>\"\n",
    "\n",
    "# You can find the account key under the _Access Keys_ link in the \n",
    "# [Azure Portal](portal.azure.com) page for your Azure storage container.\n",
    "ACCOUNT_KEY = \"<your blob storage account key>\"\n",
    "\n",
    "#-------------------------------------------------------------------------------------------\n",
    "# The data from the Data Ingestion and Preparation notebook is stored in the sensordata ingestion container.\n",
    "CONTAINER_NAME = \"sensordataingestionpm\"\n",
    "\n",
    "# Connect to your blob service     \n",
    "az_blob_service = BlockBlobService(account_name=ACCOUNT_NAME, account_key=ACCOUNT_KEY)\n",
    "\n",
    "# We will store and read each of these data sets in blob storage in an \n",
    "# Azure Storage Container on your Azure subscription.\n",
    "# See https://github.com/Azure/ViennaDocs/blob/master/Documentation/UsingBlobForStorage.md\n",
    "# for details.\n",
    "\n",
    "# This is the final feature data file.\n",
    "TRAIN_DATA = 'PM_train_files.parquet'\n",
    "TEST_DATA = 'PM_test_files.parquet'\n",
    "\n",
    "# This is where we store the final model data file.\n",
    "LOCAL_DIRECT = 'model_result.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE creating a local directory!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>RUL</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>cycle_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>119</td>\n",
       "      <td>0.643678</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.605422</td>\n",
       "      <td>0.424024</td>\n",
       "      <td>0.482613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472868</td>\n",
       "      <td>0.453604</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.326870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>120</td>\n",
       "      <td>0.189655</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.409639</td>\n",
       "      <td>0.440811</td>\n",
       "      <td>0.392302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.527132</td>\n",
       "      <td>0.530793</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.329640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>121</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.572289</td>\n",
       "      <td>0.507739</td>\n",
       "      <td>0.597907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.449612</td>\n",
       "      <td>0.544187</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.332410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>122</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.466867</td>\n",
       "      <td>0.432963</td>\n",
       "      <td>0.492404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.387597</td>\n",
       "      <td>0.603010</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.335180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>123</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400602</td>\n",
       "      <td>0.468062</td>\n",
       "      <td>0.501519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.496124</td>\n",
       "      <td>0.540182</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.337950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>52</td>\n",
       "      <td>124</td>\n",
       "      <td>0.747126</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484940</td>\n",
       "      <td>0.384783</td>\n",
       "      <td>0.493079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589147</td>\n",
       "      <td>0.502900</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.340720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>52</td>\n",
       "      <td>125</td>\n",
       "      <td>0.505747</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.406627</td>\n",
       "      <td>0.349248</td>\n",
       "      <td>0.415429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.565891</td>\n",
       "      <td>0.628556</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.343490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52</td>\n",
       "      <td>126</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.463855</td>\n",
       "      <td>0.325921</td>\n",
       "      <td>0.455773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.410853</td>\n",
       "      <td>0.552886</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.346260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52</td>\n",
       "      <td>127</td>\n",
       "      <td>0.362069</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.620482</td>\n",
       "      <td>0.373229</td>\n",
       "      <td>0.513504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.457364</td>\n",
       "      <td>0.551505</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.349030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>52</td>\n",
       "      <td>128</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.379518</td>\n",
       "      <td>0.369087</td>\n",
       "      <td>0.392640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.527132</td>\n",
       "      <td>0.524855</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.351801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle  setting1  setting2  setting3   s1        s2        s3        s4  \\\n",
       "0  52    119  0.643678  0.083333       0.0  0.0  0.605422  0.424024  0.482613   \n",
       "1  52    120  0.189655  0.833333       0.0  0.0  0.409639  0.440811  0.392302   \n",
       "2  52    121  0.500000  0.750000       0.0  0.0  0.572289  0.507739  0.597907   \n",
       "3  52    122  0.517241  0.333333       0.0  0.0  0.466867  0.432963  0.492404   \n",
       "4  52    123  0.689655  0.750000       0.0  0.0  0.400602  0.468062  0.501519   \n",
       "5  52    124  0.747126  0.666667       0.0  0.0  0.484940  0.384783  0.493079   \n",
       "6  52    125  0.505747  0.750000       0.0  0.0  0.406627  0.349248  0.415429   \n",
       "7  52    126  0.448276  0.333333       0.0  0.0  0.463855  0.325921  0.455773   \n",
       "8  52    127  0.362069  0.083333       0.0  0.0  0.620482  0.373229  0.513504   \n",
       "9  52    128  0.500000  0.166667       0.0  0.0  0.379518  0.369087  0.392640   \n",
       "\n",
       "    s5     ...      s16       s17  s18  s19       s20       s21  RUL  label1  \\\n",
       "0  0.0     ...      0.0  0.500000  0.0  0.0  0.472868  0.453604   94       0   \n",
       "1  0.0     ...      0.0  0.416667  0.0  0.0  0.527132  0.530793   93       0   \n",
       "2  0.0     ...      0.0  0.500000  0.0  0.0  0.449612  0.544187   92       0   \n",
       "3  0.0     ...      0.0  0.416667  0.0  0.0  0.387597  0.603010   91       0   \n",
       "4  0.0     ...      0.0  0.250000  0.0  0.0  0.496124  0.540182   90       0   \n",
       "5  0.0     ...      0.0  0.416667  0.0  0.0  0.589147  0.502900   89       0   \n",
       "6  0.0     ...      0.0  0.500000  0.0  0.0  0.565891  0.628556   88       0   \n",
       "7  0.0     ...      0.0  0.583333  0.0  0.0  0.410853  0.552886   87       0   \n",
       "8  0.0     ...      0.0  0.416667  0.0  0.0  0.457364  0.551505   86       0   \n",
       "9  0.0     ...      0.0  0.500000  0.0  0.0  0.527132  0.524855   85       0   \n",
       "\n",
       "   label2  cycle_norm  \n",
       "0       0    0.326870  \n",
       "1       0    0.329640  \n",
       "2       0    0.332410  \n",
       "3       0    0.335180  \n",
       "4       0    0.337950  \n",
       "5       0    0.340720  \n",
       "6       0    0.343490  \n",
       "7       0    0.346260  \n",
       "8       0    0.349030  \n",
       "9       0    0.351801  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the previous created final dataset into the workspace\n",
    "# create a local path where we store results\n",
    "if not os.path.exists(TEST_DATA):\n",
    "    os.makedirs(TEST_DATA)\n",
    "    print('DONE creating a local directory!')\n",
    "\n",
    "# download the entire parquet result folder to local path for a new run \n",
    "for blob in az_blob_service.list_blobs(CONTAINER_NAME):\n",
    "    if TRAIN_DATA in blob.name:\n",
    "        local_file = os.path.join(TEST_DATA, os.path.basename(blob.name))\n",
    "        az_blob_service.get_blob_to_path(CONTAINER_NAME, blob.name, local_file)\n",
    "        \n",
    "test_df = spark.read.parquet(TEST_DATA)\n",
    "test_df = test_df.toPandas()\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json file read from shared folder\n"
     ]
    }
   ],
   "source": [
    "with open(os.environ['AZUREML_NATIVE_SHARE_DIRECTORY'] + 'modellstm.json', 'r') as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    print(\"json file read from shared folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model weights read from shared folder\n"
     ]
    }
   ],
   "source": [
    "with open(os.environ['AZUREML_NATIVE_SHARE_DIRECTORY'] + 'modellstm.h5', 'r') as model:\n",
    "    loaded_model.load_weights(os.path.join(os.environ['AZUREML_NATIVE_SHARE_DIRECTORY'], 'modellstm.h5'))\n",
    "    print(\"model weights read from shared folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test init() and run() functions to read from the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a large window size of 50 cycles\n",
    "sequence_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    # read in the model file\n",
    "    from keras.models import model_from_json\n",
    "\n",
    "    # load json and create model\n",
    "    with open(os.environ['AZUREML_NATIVE_SHARE_DIRECTORY'] + 'modellstm.json', 'r') as json_file:\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    with open(os.environ['AZUREML_NATIVE_SHARE_DIRECTORY'] + 'modellstm.h5', 'r') as model:\n",
    "        print(\"Loaded model\")\n",
    "    \n",
    "    #inputs_dc = ModelDataCollector(\"modellstm.h5\", identifier=\"inputs\")\n",
    "    #print(inputs_dc)\n",
    "    #prediction_dc = ModelDataCollector(\"modellstm.h5\", identifier=\"prediction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sequence(id_df, seq_length, seq_cols):\n",
    "    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n",
    "    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n",
    "    we can use shorter ones \"\"\"\n",
    "    data_array = id_df[seq_cols].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
    "        yield data_array[start:stop, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the feature columns \n",
    "sensor_cols = ['s' + str(i) for i in range(1,22)]\n",
    "sequence_cols = ['setting1', 'setting2', 'setting3', 'cycle_norm']\n",
    "input_features = sensor_cols + sequence_cols\n",
    "input_features\n",
    "sequence_cols.extend(sensor_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator for the sequences\n",
    "seq_gen = (list(gen_sequence(test_df[test_df['id']==id], sequence_length, sequence_cols)) \n",
    "           for id in test_df['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15631, 50, 25)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate sequences and convert to numpy array\n",
    "seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
    "seq_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(seq_array): \n",
    "    global clf2, inputs_dc, prediction_dc\n",
    "    try:\n",
    "        prediction = loaded_model.predict_proba(seq_array)\n",
    "        #print(prediction)\n",
    "        #inputs_dc.collect(seq_array)\n",
    "        #prediction_dc.collect(prediction)\n",
    "        return (prediction)\n",
    "    except Exception as e:\n",
    "        return(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02161   ],\n",
       "       [0.0240796 ],\n",
       "       [0.02850101],\n",
       "       ...,\n",
       "       [0.9828591 ],\n",
       "       [0.98365027],\n",
       "       [0.9840912 ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = loaded_model.predict_proba(seq_array)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model\n"
     ]
    }
   ],
   "source": [
    "init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02161   ],\n",
       "       [0.0240796 ],\n",
       "       [0.02850101],\n",
       "       ...,\n",
       "       [0.9828591 ],\n",
       "       [0.98365027],\n",
       "       [0.9840912 ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(seq_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist model assets\n",
    "\n",
    "Next we persist the assets we have created to disk for use in operationalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /azureml-share//lstmscore.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {os.environ['AZUREML_NATIVE_SHARE_DIRECTORY']}/lstmscore.py\n",
    "\n",
    "import keras\n",
    "# import the libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "# Setting seed for reproducability\n",
    "np.random.seed(1234)  \n",
    "PYTHONHASHSEED = 0\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation\n",
    "\n",
    "def init():\n",
    "    # read in the model file\n",
    "    from keras.models import model_from_json\n",
    "\n",
    "    # load json and create model\n",
    "    json_file = open('modellstm.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"modellstm.h5\")\n",
    "    print(\"Loaded model\")\n",
    "    \n",
    "    #inputs_dc = ModelDataCollector(\"modellstm.h5\", identifier=\"inputs\")\n",
    "    #print(inputs_dc)\n",
    "    #prediction_dc = ModelDataCollector(\"modellstm.h5\", identifier=\"prediction\")\n",
    "    \n",
    "    \n",
    "def run(seq_array): \n",
    "    global clf2, inputs_dc, prediction_dc\n",
    "    try:\n",
    "        prediction = loaded_model.predict_proba(seq_array)\n",
    "        #print(prediction)\n",
    "        #inputs_dc.collect(seq_array)\n",
    "        #prediction_dc.collect(prediction)\n",
    "        return (prediction)\n",
    "    except Exception as e:\n",
    "        return(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving the files from the shared folder:\n",
    "https://docs.microsoft.com/en-us/azure/machine-learning/preview/how-to-read-write-files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment\n",
    "\n",
    "Once the assets are stored, we can download them into a local compute context for operationalization on an Azure web service.\n",
    "\n",
    "We demonstrate how to setup this web service this through a CLI window opened in the AML Workbench application. \n",
    "\n",
    "Once downloaded, unzip the file into the directory of your choosing. The zip file contains three deployment assets:\n",
    "\n",
    "- the `lstmscore.py` file\n",
    "- a `lstm.model` directory\n",
    "- the `modellstm.json` file\n",
    "\n",
    "\n",
    "\n",
    "## Create a model management endpoint \n",
    "\n",
    "Create a modelmanagement under your account. We will call this `lstmmodelmanagement`. The remaining defaults are acceptable.\n",
    "\n",
    "`az ml account modelmanagement create --location <ACCOUNT_REGION> --resource-group <RESOURCE_GROUP> --name pdmmodelmanagement`\n",
    "\n",
    "\n",
    "## Check environment settings\n",
    "\n",
    "Show what environment is currently active:\n",
    "\n",
    "`az ml env show`\n",
    "\n",
    "If nothing is set, we setup the environment with the existing model management context first: \n",
    "\n",
    "` az ml env setup --location <ACCOUNT_REGION> --resource-group <RESOURCE_GROUP> --name pdmmodelmanagement`\n",
    "\n",
    "then set the current environment:\n",
    "\n",
    "`az ml env set --resource-group <RESOURCE_GROUP> --cluster-name pdmmodelmanagement`\n",
    "\n",
    "Check that the environment is now set:\n",
    "\n",
    "`az ml env show`\n",
    "\n",
    "\n",
    "## Deploy your web service \n",
    "\n",
    "Once the environment is setup, we'll deploy the web service from the CLI.\n",
    "\n",
    "These commands assume the current directory contains the webservice assets we created in throughout the notebooks in this scenario (`lstmscore.py`, `modellstm.json` and `lstm.model`). If your kernel has run locally, the assets will be in the `os.environ['AZUREML_NATIVE_SHARE_DIRECTORY']`. \n",
    "\n",
    "On windows this points to:\n",
    "\n",
    "```\n",
    "cd C:\\Users\\<username>\\.azureml\\share\\<team account>\\<Project Name>\n",
    "```\n",
    "\n",
    "on linux variants this points to:\n",
    "\n",
    "```\n",
    "cd ~\\.azureml\\share\\<team account>\\<Project Name>\n",
    "```\n",
    "\n",
    "\n",
    "The command to create a web service (`<SERVICE_ID>`) with these operationalization assets in the current directory is:\n",
    "\n",
    "```\n",
    "az ml service create realtime -f <filename> -r <TARGET_RUNTIME> -m <MODEL_FILE> -s <SCHEMA_FILE> -n <SERVICE_ID> --cpu 0.1\n",
    "```\n",
    "\n",
    "The default cluster has only 2 nodes with 2 cores each. Some cores are taken for system components. AMLWorkbench asks for 1 core per service. To deploy multiple services into this cluster, we specify the cpu requirement in the service create command as (--cpu 0.1) to request 10% of a core. \n",
    "\n",
    "For this example, we will call our webservice `amlworkbenchpdmwebservice`. This `SERVICE_ID` must be all lowercase, with no spaces:\n",
    "\n",
    "```\n",
    "az ml service create realtime -f lstmscore.py -r spark-py -m lstm.model -s modellstm.json --cpu 0.1 -n amlworkbenchpdmwebservice\n",
    "```\n",
    "\n",
    "This command will take some time to execute. \n",
    "\n",
    "Once complete, the command returns sample usage commands to test the service for both PowerShell and the cmd prompt. We can execute these commands from the command line as well."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "LSTM dsvm",
   "language": "python",
   "name": "lstm_dsvm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
