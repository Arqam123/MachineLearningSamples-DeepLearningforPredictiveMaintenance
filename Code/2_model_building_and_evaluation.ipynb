{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Step 2: Model Building\n",
    "Using the sensor data sets explored and constructed in the `1_data_ingestion_and_preparation.ipynb` Jupyter notebook, this notebook loads the data from the Azure Blob container and builds a LSTM network for scenerio described at [Predictive Maintenance Template](https://gallery.cortanaintelligence.com/Collection/Predictive-Maintenance-Template-3) to predict remaining useful life of aircraft engines. We then store the model for deployment in an Azure web service. We will prepare and build the web service in the `Code/3_operationalization.ipynb` Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "import h5py\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import urllib\n",
    "import glob\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "# Setup the pyspark environment\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Setting seed for reproducability\n",
    "np.random.seed(1234)  \n",
    "PYTHONHASHSEED = 0\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "from keras.models import Sequential\n",
    "from sklearn import datasets\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation\n",
    "\n",
    "# Use the Azure Machine Learning data collector to log various metrics\n",
    "from azureml.logging import get_azureml_logger\n",
    "\n",
    "# For Azure blob storage access\n",
    "from azure.storage.blob import BlockBlobService\n",
    "from azure.storage.blob import PublicAccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azureml.logging.script_run_request.ScriptRunRequest at 0x7f4509242a58>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.logging import get_azureml_logger\n",
    "run_logger = get_azureml_logger()\n",
    "run_logger.log('amlrealworld.predictivemaintenanceforpm.modelbuildingandevaluation','true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load feature data set\n",
    "\n",
    "We have previously created the labeled data set in the `Code\\1_Data Ingestion and Preparation.ipynb` Jupyter notebook. Since the Azure Blob storage account name and account key are not passed between notebooks, you'll need your credentials here again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Azure blob storage details here \n",
    "ACCOUNT_NAME = \"<your blob storage account name>\"\n",
    "\n",
    "# You can find the account key under the _Access Keys_ link in the \n",
    "# [Azure Portal](portal.azure.com) page for your Azure storage container.\n",
    "ACCOUNT_KEY = \"<your blob storage account key>\"\n",
    "#-------------------------------------------------------------------------------------------\n",
    "# The data from the Data Ingestion and Preparation notebook is stored in the sensordata ingestion container.\n",
    "CONTAINER_NAME = \"sensordataingestionpm\"\n",
    "\n",
    "# Connect to your blob service     \n",
    "az_blob_service = BlockBlobService(account_name=ACCOUNT_NAME, account_key=ACCOUNT_KEY)\n",
    "\n",
    "# We will store and read each of these data sets in blob storage in an \n",
    "# Azure Storage Container on your Azure subscription.\n",
    "# See https://github.com/Azure/ViennaDocs/blob/master/Documentation/UsingBlobForStorage.md\n",
    "# for details.\n",
    "\n",
    "# This is the final feature data file.\n",
    "TRAIN_DATA = 'PM_train_files.parquet'\n",
    "TEST_DATA = 'PM_test_files.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and dump a short summary of the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE creating a local directory!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>RUL</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>cycle_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>119</td>\n",
       "      <td>0.643678</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.605422</td>\n",
       "      <td>0.424024</td>\n",
       "      <td>0.482613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472868</td>\n",
       "      <td>0.453604</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.326870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>120</td>\n",
       "      <td>0.189655</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.409639</td>\n",
       "      <td>0.440811</td>\n",
       "      <td>0.392302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.527132</td>\n",
       "      <td>0.530793</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.329640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>121</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.572289</td>\n",
       "      <td>0.507739</td>\n",
       "      <td>0.597907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.449612</td>\n",
       "      <td>0.544187</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.332410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>122</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.466867</td>\n",
       "      <td>0.432963</td>\n",
       "      <td>0.492404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.387597</td>\n",
       "      <td>0.603010</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.335180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>123</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400602</td>\n",
       "      <td>0.468062</td>\n",
       "      <td>0.501519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.496124</td>\n",
       "      <td>0.540182</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.337950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>52</td>\n",
       "      <td>124</td>\n",
       "      <td>0.747126</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484940</td>\n",
       "      <td>0.384783</td>\n",
       "      <td>0.493079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589147</td>\n",
       "      <td>0.502900</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.340720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>52</td>\n",
       "      <td>125</td>\n",
       "      <td>0.505747</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.406627</td>\n",
       "      <td>0.349248</td>\n",
       "      <td>0.415429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.565891</td>\n",
       "      <td>0.628556</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.343490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52</td>\n",
       "      <td>126</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.463855</td>\n",
       "      <td>0.325921</td>\n",
       "      <td>0.455773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.410853</td>\n",
       "      <td>0.552886</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.346260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52</td>\n",
       "      <td>127</td>\n",
       "      <td>0.362069</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.620482</td>\n",
       "      <td>0.373229</td>\n",
       "      <td>0.513504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.457364</td>\n",
       "      <td>0.551505</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.349030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>52</td>\n",
       "      <td>128</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.379518</td>\n",
       "      <td>0.369087</td>\n",
       "      <td>0.392640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.527132</td>\n",
       "      <td>0.524855</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.351801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle  setting1  setting2  setting3   s1        s2        s3        s4  \\\n",
       "0  52    119  0.643678  0.083333       0.0  0.0  0.605422  0.424024  0.482613   \n",
       "1  52    120  0.189655  0.833333       0.0  0.0  0.409639  0.440811  0.392302   \n",
       "2  52    121  0.500000  0.750000       0.0  0.0  0.572289  0.507739  0.597907   \n",
       "3  52    122  0.517241  0.333333       0.0  0.0  0.466867  0.432963  0.492404   \n",
       "4  52    123  0.689655  0.750000       0.0  0.0  0.400602  0.468062  0.501519   \n",
       "5  52    124  0.747126  0.666667       0.0  0.0  0.484940  0.384783  0.493079   \n",
       "6  52    125  0.505747  0.750000       0.0  0.0  0.406627  0.349248  0.415429   \n",
       "7  52    126  0.448276  0.333333       0.0  0.0  0.463855  0.325921  0.455773   \n",
       "8  52    127  0.362069  0.083333       0.0  0.0  0.620482  0.373229  0.513504   \n",
       "9  52    128  0.500000  0.166667       0.0  0.0  0.379518  0.369087  0.392640   \n",
       "\n",
       "    s5     ...      s16       s17  s18  s19       s20       s21  RUL  label1  \\\n",
       "0  0.0     ...      0.0  0.500000  0.0  0.0  0.472868  0.453604   94       0   \n",
       "1  0.0     ...      0.0  0.416667  0.0  0.0  0.527132  0.530793   93       0   \n",
       "2  0.0     ...      0.0  0.500000  0.0  0.0  0.449612  0.544187   92       0   \n",
       "3  0.0     ...      0.0  0.416667  0.0  0.0  0.387597  0.603010   91       0   \n",
       "4  0.0     ...      0.0  0.250000  0.0  0.0  0.496124  0.540182   90       0   \n",
       "5  0.0     ...      0.0  0.416667  0.0  0.0  0.589147  0.502900   89       0   \n",
       "6  0.0     ...      0.0  0.500000  0.0  0.0  0.565891  0.628556   88       0   \n",
       "7  0.0     ...      0.0  0.583333  0.0  0.0  0.410853  0.552886   87       0   \n",
       "8  0.0     ...      0.0  0.416667  0.0  0.0  0.457364  0.551505   86       0   \n",
       "9  0.0     ...      0.0  0.500000  0.0  0.0  0.527132  0.524855   85       0   \n",
       "\n",
       "   label2  cycle_norm  \n",
       "0       0    0.326870  \n",
       "1       0    0.329640  \n",
       "2       0    0.332410  \n",
       "3       0    0.335180  \n",
       "4       0    0.337950  \n",
       "5       0    0.340720  \n",
       "6       0    0.343490  \n",
       "7       0    0.346260  \n",
       "8       0    0.349030  \n",
       "9       0    0.351801  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the previous created final dataset into the workspace\n",
    "# create a local path where we store results\n",
    "if not os.path.exists(TRAIN_DATA):\n",
    "    os.makedirs(TRAIN_DATA)\n",
    "    print('DONE creating a local directory!')\n",
    "\n",
    "# download the entire parquet result folder to local path for a new run \n",
    "for blob in az_blob_service.list_blobs(CONTAINER_NAME):\n",
    "    if TRAIN_DATA in blob.name:\n",
    "        local_file = os.path.join(TRAIN_DATA, os.path.basename(blob.name))\n",
    "        az_blob_service.get_blob_to_path(CONTAINER_NAME, blob.name, local_file)\n",
    "\n",
    "train_df = spark.read.parquet(TRAIN_DATA)\n",
    "train_df = train_df.toPandas()\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE creating a local directory!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>cycle_norm</th>\n",
       "      <th>RUL</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>183</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.334337</td>\n",
       "      <td>0.430783</td>\n",
       "      <td>0.325625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.737365</td>\n",
       "      <td>0.504155</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>184</td>\n",
       "      <td>0.436782</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.331325</td>\n",
       "      <td>0.378897</td>\n",
       "      <td>0.573093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.596899</td>\n",
       "      <td>0.736537</td>\n",
       "      <td>0.506925</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>185</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.439759</td>\n",
       "      <td>0.311969</td>\n",
       "      <td>0.335584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.612403</td>\n",
       "      <td>0.772991</td>\n",
       "      <td>0.509695</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>186</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.340361</td>\n",
       "      <td>0.235448</td>\n",
       "      <td>0.253545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550388</td>\n",
       "      <td>0.649268</td>\n",
       "      <td>0.512465</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>187</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400602</td>\n",
       "      <td>0.268367</td>\n",
       "      <td>0.325625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.565891</td>\n",
       "      <td>0.698840</td>\n",
       "      <td>0.515235</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>49</td>\n",
       "      <td>188</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.319277</td>\n",
       "      <td>0.426641</td>\n",
       "      <td>0.324949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.596899</td>\n",
       "      <td>0.653963</td>\n",
       "      <td>0.518006</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49</td>\n",
       "      <td>189</td>\n",
       "      <td>0.471264</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.427711</td>\n",
       "      <td>0.308044</td>\n",
       "      <td>0.225861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.620155</td>\n",
       "      <td>0.698288</td>\n",
       "      <td>0.520776</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>49</td>\n",
       "      <td>190</td>\n",
       "      <td>0.718391</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.487952</td>\n",
       "      <td>0.390669</td>\n",
       "      <td>0.367995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.588373</td>\n",
       "      <td>0.523546</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>49</td>\n",
       "      <td>191</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.219880</td>\n",
       "      <td>0.370395</td>\n",
       "      <td>0.285618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.605220</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>49</td>\n",
       "      <td>192</td>\n",
       "      <td>0.442529</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.358434</td>\n",
       "      <td>0.235884</td>\n",
       "      <td>0.410702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.612403</td>\n",
       "      <td>0.743303</td>\n",
       "      <td>0.529086</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle  setting1  setting2  setting3   s1        s2        s3        s4  \\\n",
       "0  49    183  0.500000  0.333333       0.0  0.0  0.334337  0.430783  0.325625   \n",
       "1  49    184  0.436782  0.916667       0.0  0.0  0.331325  0.378897  0.573093   \n",
       "2  49    185  0.448276  0.916667       0.0  0.0  0.439759  0.311969  0.335584   \n",
       "3  49    186  0.609195  0.416667       0.0  0.0  0.340361  0.235448  0.253545   \n",
       "4  49    187  0.448276  0.416667       0.0  0.0  0.400602  0.268367  0.325625   \n",
       "5  49    188  0.666667  0.583333       0.0  0.0  0.319277  0.426641  0.324949   \n",
       "6  49    189  0.471264  0.166667       0.0  0.0  0.427711  0.308044  0.225861   \n",
       "7  49    190  0.718391  0.166667       0.0  0.0  0.487952  0.390669  0.367995   \n",
       "8  49    191  0.431034  0.416667       0.0  0.0  0.219880  0.370395  0.285618   \n",
       "9  49    192  0.442529  0.416667       0.0  0.0  0.358434  0.235884  0.410702   \n",
       "\n",
       "    s5   ...    s16       s17  s18  s19       s20       s21  cycle_norm  RUL  \\\n",
       "0  0.0   ...    0.0  0.333333  0.0  0.0  0.511628  0.737365    0.504155  141   \n",
       "1  0.0   ...    0.0  0.333333  0.0  0.0  0.596899  0.736537    0.506925  140   \n",
       "2  0.0   ...    0.0  0.333333  0.0  0.0  0.612403  0.772991    0.509695  139   \n",
       "3  0.0   ...    0.0  0.416667  0.0  0.0  0.550388  0.649268    0.512465  138   \n",
       "4  0.0   ...    0.0  0.583333  0.0  0.0  0.565891  0.698840    0.515235  137   \n",
       "5  0.0   ...    0.0  0.583333  0.0  0.0  0.596899  0.653963    0.518006  136   \n",
       "6  0.0   ...    0.0  0.250000  0.0  0.0  0.620155  0.698288    0.520776  135   \n",
       "7  0.0   ...    0.0  0.333333  0.0  0.0  0.573643  0.588373    0.523546  134   \n",
       "8  0.0   ...    0.0  0.500000  0.0  0.0  0.604651  0.605220    0.526316  133   \n",
       "9  0.0   ...    0.0  0.333333  0.0  0.0  0.612403  0.743303    0.529086  132   \n",
       "\n",
       "   label1  label2  \n",
       "0       0       0  \n",
       "1       0       0  \n",
       "2       0       0  \n",
       "3       0       0  \n",
       "4       0       0  \n",
       "5       0       0  \n",
       "6       0       0  \n",
       "7       0       0  \n",
       "8       0       0  \n",
       "9       0       0  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the previous created final dataset into the workspace\n",
    "# create a local path where we store results\n",
    "if not os.path.exists(TEST_DATA):\n",
    "    os.makedirs(TEST_DATA)\n",
    "    print('DONE creating a local directory!')\n",
    "\n",
    "# download the entire parquet result folder to local path for a new run \n",
    "for blob in az_blob_service.list_blobs(CONTAINER_NAME):\n",
    "    if TEST_DATA in blob.name:\n",
    "        local_file = os.path.join(TEST_DATA, os.path.basename(blob.name))\n",
    "        az_blob_service.get_blob_to_path(CONTAINER_NAME, blob.name, local_file)\n",
    "        \n",
    "test_df = spark.read.parquet(TEST_DATA)\n",
    "test_df = test_df.toPandas()\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "The traditional predictive maintenance machine learning models are based on feature engineering which is manual construction of right features using domain expertise and similar methods. This usually makes these models hard to reuse since feature engineering is specific to the problem scenario and the available data which varies from one business to the other. Perhaps the most attractive part of applying deep learning in the predictive maintenance domain is the fact that these networks can automatically extract the right features from the data, eliminating the need for manual feature engineering.\n",
    "\n",
    "When using LSTMs in the time-series domain, one important parameter to pick is the sequence length which is the window for LSTMs to look back. This may be viewed as similar to picking window_size = 5 cycles for calculating the rolling features in the [Predictive Maintenance Template](https://gallery.cortanaintelligence.com/Collection/Predictive-Maintenance-Template-3) which are rolling mean and rolling standard deviation for 21 sensor values. The idea of using LSTMs is to let the model extract abstract features out of the sequence of sensor values in the window rather than engineering those manually. The expectation is that if there is a pattern in these sensor values within the window prior to failure, the pattern should be encoded by the LSTM.\n",
    "\n",
    "One critical advantage of LSTMs is their ability to remember from long-term sequences (window sizes) which is hard to achieve by traditional feature engineering. For example, computing rolling averages over a window size of 50 cycles may lead to loss of information due to smoothing and abstracting of values over such a long period, istead, using all 50 values as input may provide better results. While feature engineering over large window sizes may not make sense, LSTMs are able to use larger window sizes and use all the information in the window as input. Below, we illustrate the approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a large window size of 50 cycles\n",
    "sequence_length = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Keras LSTM](https://keras.io/layers/recurrent/) layers expect an input in the shape of a numpy array of 3 dimensions (samples, time steps, features) where samples is the number of training sequences, time steps is the look back window or sequence length and features is the number of features of each sequence at each time step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to reshape features into (samples, time steps, features) \n",
    "def gen_sequence(id_df, seq_length, seq_cols):\n",
    "    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n",
    "    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n",
    "    we can use shorter ones \"\"\"\n",
    "    data_array = id_df[seq_cols].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
    "        yield data_array[start:stop, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the feature columns \n",
    "sensor_cols = ['s' + str(i) for i in range(1,22)]\n",
    "sequence_cols = ['setting1', 'setting2', 'setting3', 'cycle_norm']\n",
    "input_features = sensor_cols + sequence_cols\n",
    "input_features\n",
    "sequence_cols.extend(sensor_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator for the sequences\n",
    "seq_gen = (list(gen_sequence(train_df[train_df['id']==id], sequence_length, sequence_cols)) \n",
    "           for id in train_df['id'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15631, 50, 25)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate sequences and convert to numpy array\n",
    "seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
    "seq_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate labels\n",
    "def gen_labels(id_df, seq_length, label):\n",
    "    data_array = id_df[label].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    return data_array[seq_length:num_elements, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15631, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate labels\n",
    "label_gen = [gen_labels(train_df[train_df['id']==id], sequence_length, ['label1']) \n",
    "             for id in train_df['id'].unique()]\n",
    "label_array = np.concatenate(label_gen).astype(np.float32)\n",
    "label_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Network\n",
    "\n",
    "Next, we build a deep network. The first layer is a LSTM layer with 100 units followed by another LSTM layer with 50 units. Dropout is also applied after each LSTM layer to control overfitting. Final layer is a Dense output layer with single unit and sigmoid activation since this is a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the network\n",
    "nb_features = seq_array.shape[2]\n",
    "nb_out = label_array.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(\n",
    "         input_shape=(sequence_length, nb_features),\n",
    "         units=100,\n",
    "         return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(\n",
    "          units=50,\n",
    "          return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=nb_out, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 50, 100)           50400     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 80,651\n",
      "Trainable params: 80,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14849 samples, validate on 782 samples\n",
      "Epoch 1/10\n",
      "14849/14849 [==============================] - 17s 1ms/step - loss: 0.2624 - acc: 0.8895 - val_loss: 0.1817 - val_acc: 0.9105\n",
      "Epoch 2/10\n",
      "14849/14849 [==============================] - 16s 1ms/step - loss: 0.1076 - acc: 0.9572 - val_loss: 0.0727 - val_acc: 0.9757\n",
      "Epoch 3/10\n",
      "14849/14849 [==============================] - 16s 1ms/step - loss: 0.0914 - acc: 0.9634 - val_loss: 0.0977 - val_acc: 0.9591\n",
      "CPU times: user 3min, sys: 48.1 s, total: 3min 48s\n",
      "Wall time: 50.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4508122b38>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# fit the network\n",
    "model.fit(seq_array, label_array, epochs=10, batch_size=200, validation_split=0.05, verbose=1,\n",
    "          callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15631/15631 [==============================] - 5s 342us/step\n",
      "Accurracy: 0.9485637493573135\n"
     ]
    }
   ],
   "source": [
    "# training metrics\n",
    "scores = model.evaluate(seq_array, label_array, verbose=1, batch_size=200)\n",
    "print('Accurracy: {}'.format(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15631/15631 [==============================] - 5s 348us/step\n",
      "Confusion matrix\n",
      "- x-axis is true labels.\n",
      "- y-axis is predicted labels\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[12503,    37],\n",
       "       [  767,  2324]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions and compute confusion matrix\n",
    "y_pred = model.predict_classes(seq_array,verbose=1, batch_size=200)\n",
    "y_true = label_array\n",
    "print('Confusion matrix\\n- x-axis is true labels.\\n- y-axis is predicted labels')\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision =  0.9843286742905548 \n",
      " recall =  0.7518602394047234\n"
     ]
    }
   ],
   "source": [
    "# compute precision and recall\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "print( 'precision = ', precision, '\\n', 'recall = ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we look at the performance on the test data. Only the last cycle data for each engine id in the test data is kept for testing purposes. In order to compare the results to the template, we pick the last sequence for each id in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93, 50, 25)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_array_test_last = [test_df[test_df['id']==id][sequence_cols].values[-sequence_length:] \n",
    "                       for id in test_df['id'].unique() if len(test_df[test_df['id']==id]) >= sequence_length]\n",
    "\n",
    "seq_array_test_last = np.asarray(seq_array_test_last).astype(np.float32)\n",
    "seq_array_test_last.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mask = [len(test_df[test_df['id']==id]) >= sequence_length for id in test_df['id'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_array_test_last = test_df.groupby('id')['label1'].nth(-1)[y_mask].values\n",
    "label_array_test_last = label_array_test_last.reshape(label_array_test_last.shape[0],1).astype(np.float32)\n",
    "label_array_test_last.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 50, 25)\n",
      "(93, 1)\n"
     ]
    }
   ],
   "source": [
    "print(seq_array_test_last.shape)\n",
    "print(label_array_test_last.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurracy: 0.6881720398062019\n"
     ]
    }
   ],
   "source": [
    "# test metrics\n",
    "scores_test = model.evaluate(seq_array_test_last, label_array_test_last, verbose=2)\n",
    "print('Accurracy: {}'.format(scores_test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "- x-axis is true labels.\n",
      "- y-axis is predicted labels\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[61, 11],\n",
       "       [18,  3]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions and compute confusion matrix\n",
    "y_pred_test = model.predict_classes(seq_array_test_last)\n",
    "y_true_test = label_array_test_last\n",
    "print('Confusion matrix\\n- x-axis is true labels.\\n- y-axis is predicted labels')\n",
    "cm = confusion_matrix(y_true_test, y_pred_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.21428571428571427 \n",
      " Recall:  0.14285714285714285 \n",
      " F1-score: 0.17142857142857143\n"
     ]
    }
   ],
   "source": [
    "# compute precision and recall\n",
    "precision_test = precision_score(y_true_test, y_pred_test)\n",
    "recall_test = recall_score(y_true_test, y_pred_test)\n",
    "f1_test = 2 * (precision_test * recall_test) / (precision_test + recall_test)\n",
    "print( 'Precision: ', precision_test, '\\n', 'Recall: ', recall_test,'\\n', 'F1-score:', f1_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving/loading the model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving a copy of the file\n",
    "model_cp = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.models.Sequential at 0x7f45085be400>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and test the loaded model locally first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "# Save the model for operationalization: https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "import os\n",
    "import h5py\n",
    "from sklearn import datasets \n",
    " \n",
    "# save model\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"modellstm.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"modellstm.h5\")\n",
    "print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('modellstm.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"modellstm.h5\")\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15631/15631 [==============================] - 10s 645us/step\n",
      "(15631, 1)\n",
      "[[0.02161   ]\n",
      " [0.0240796 ]\n",
      " [0.02850101]\n",
      " ...\n",
      " [0.9828591 ]\n",
      " [0.98365027]\n",
      " [0.9840912 ]]\n"
     ]
    }
   ],
   "source": [
    "score = loaded_model.predict_proba(seq_array,verbose=1)\n",
    "print(score.shape)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the files to the shared folder for operationalization\n",
    "https://docs.microsoft.com/en-us/azure/machine-learning/preview/how-to-read-write-files\n",
    "\n",
    "#### Ubuntu Linux\n",
    "/home/<username>/ then navigate to .azureml/share/<exp_acct_name>/<workspace_name>/<proj_name>/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json file written shared folder\n"
     ]
    }
   ],
   "source": [
    "with open(os.environ['AZUREML_NATIVE_SHARE_DIRECTORY'] + 'modellstm.json', 'wt') as json_file:\n",
    "    json_file.write(model_json)\n",
    "    print(\"json file written shared folder\")\n",
    "    json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cp.save_weights(os.path.join(os.environ['AZUREML_NATIVE_SHARE_DIRECTORY'], 'modellstm.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In the next notebook `Code/3_operationalization.ipynb` Jupyter notebook we will create the functions needed to operationalize and deploy any model to get realtime predictions."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "LSTM dsvm",
   "language": "python",
   "name": "lstm_dsvm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
