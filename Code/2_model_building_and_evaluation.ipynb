{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Predictive Maintenance\n",
    "\n",
    "Deep learning is one of the hottest trends in the machine learning space nowadays, and there are many fields and applications where it stands out, such as driverless cars, speech and image recognition, robotics and finance. Deep learning is a set of algorithms that is inspired by the shape of our brain (biological neural networks), and machine learning and cognitive scientists usually refer to it as Artificial Neural Networks (ANN).\n",
    "\n",
    "Predictive maintenance is also a very popular area where many different techniques are designed to help determine the condition of an equipment in order to predict when maintenance should be performed. In predictive maintenance scenarios, data is collected over time to monitor the state of an equipment with the final goal of finding patterns to predict failures. Among the deep learning methods, Long Short Term Memory [(LSTM)](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) networks are especially appealing to the predictive maintenance domain due to the fact that they are very good at learning from sequences. This fact lends itself to their applications using time series data by making it possible to look back for longer periods of time to detect failure patterns. \n",
    "\n",
    "In this notebook, we build an LSTM network for the data set and scenerio described at [Predictive Maintenance Template](https://gallery.cortanaintelligence.com/Collection/Predictive-Maintenance-Template-3) to predict remaining useful life of aircraft engines. In summary, the template uses simulated aircraft sensor values to predict when an aircraft engine will fail in the future so that maintenance can be planned in advance. \n",
    "\n",
    "This notebook serves as a tutorial for beginners looking to apply deep learning in predictive maintenance domain and uses a simple scenario where only one data source (sensor values) is used to make predictions. In more advanced predictive maintenance scenarios such as in [Predictive Maintenance Modelling Guide](https://gallery.cortanaintelligence.com/Notebook/Predictive-Maintenance-Modelling-Guide-R-Notebook-1), there are many other data sources (i.e. historical maintenance records, error logs, machine and operator features etc.) which may require different types of treatments to be used in the deep learning networks. Since predictive maintenance is not a typical domain for deep learning, its application is an open area of research. \n",
    "\n",
    "This notebook uses [keras](https://keras.io/) deep learning library with Microsoft Cognitive Toolkit [CNTK](https://docs.microsoft.com/en-us/cognitive-toolkit/Using-CNTK-with-Keras) as backend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 2: Model Building\n",
    "\n",
    "Using the sensor data sets explored and constructed in the `1_Data Ingestion and Preparation.ipynb` Jupyter notebook, this notebook loads the data from the Azure Blob container and builds an LSTM network for scenerio described at [Predictive Maintenance Template](https://gallery.cortanaintelligence.com/Collection/Predictive-Maintenance-Template-3) to predict remaining useful life of aircraft engines. We then store the model for deployment in an Azure web service. We will prepare and build the web service in the `Code/3_Operationalization.ipynb` Jupyter notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "from scipy import stats\n",
    "\n",
    "# Setup the pyspark environment\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Setting seed for reproducability\n",
    "np.random.seed(1234)  \n",
    "PYTHONHASHSEED = 0\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation\n",
    "%matplotlib inline\n",
    "\n",
    "# For Azure blob storage access\n",
    "from azure.storage.blob import BlockBlobService\n",
    "from azure.storage.blob import PublicAccess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load feature data set\n",
    "\n",
    "We have previously created the labeled feature data set in the `Code\\1_Data Ingestion and Preparation.ipynb` Jupyter notebook. Since the Azure Blob storage account name and account key are not passed between notebooks, you'll need your credentials here again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your Azure blob storage details here \n",
    "#ACCOUNT_NAME = \"<your blob storage account name>\"\n",
    "ACCOUNT_NAME = \"mlsamplespmfrancesca638\"\n",
    "\n",
    "# You can find the account key under the _Access Keys_ link in the \n",
    "# [Azure Portal](portal.azure.com) page for your Azure storage container.\n",
    "#ACCOUNT_KEY = \"<your blob storage account key>\"\n",
    "ACCOUNT_KEY = \"eeoYWNozGWaFq6mykM1ZTTcCDX+mHElWCpooqO2fYIZhFOC5W9JsZkxDROCsfzNmANSm+WM6l+tXZFDwUjB+3A==\"\n",
    "\n",
    "#-------------------------------------------------------------------------------------------\n",
    "# The data from the Data Ingestion and Preparation notebook is stored in the sensordata ingestion container.\n",
    "CONTAINER_NAME = \"sensordataingestiontest\"\n",
    "\n",
    "# Connect to your blob service     \n",
    "az_blob_service = BlockBlobService(account_name=ACCOUNT_NAME, account_key=ACCOUNT_KEY)\n",
    "\n",
    "# We will store and read each of these data sets in blob storage in an \n",
    "# Azure Storage Container on your Azure subscription.\n",
    "# See https://github.com/Azure/ViennaDocs/blob/master/Documentation/UsingBlobForStorage.md\n",
    "# for details.\n",
    "\n",
    "# This is the final feature data file. #FEATURES_LOCAL_DIRECT\n",
    "TRAIN_DATA = 'PM_train_files.parquet'\n",
    "TEST_DATA = 'PM_test_files.parquet'\n",
    "\n",
    "# This is where we store the final model data file.\n",
    "LOCAL_DIRECT = 'model_result.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and dump a short summary of the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE creating a local directory!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>RUL</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>cycle_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86</td>\n",
       "      <td>69</td>\n",
       "      <td>0.591954</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.439759</td>\n",
       "      <td>0.450621</td>\n",
       "      <td>0.380655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.567109</td>\n",
       "      <td>209</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.188366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86</td>\n",
       "      <td>70</td>\n",
       "      <td>0.356322</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472892</td>\n",
       "      <td>0.496621</td>\n",
       "      <td>0.293889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.536868</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.191136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "      <td>71</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.496988</td>\n",
       "      <td>0.348812</td>\n",
       "      <td>0.447670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.457364</td>\n",
       "      <td>0.624827</td>\n",
       "      <td>207</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.193906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>72</td>\n",
       "      <td>0.454023</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.289157</td>\n",
       "      <td>0.306736</td>\n",
       "      <td>0.451047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550388</td>\n",
       "      <td>0.579674</td>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.196676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>73</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.409639</td>\n",
       "      <td>0.418574</td>\n",
       "      <td>0.362762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.612403</td>\n",
       "      <td>0.615576</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.199446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>86</td>\n",
       "      <td>74</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484940</td>\n",
       "      <td>0.296926</td>\n",
       "      <td>0.294227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.579950</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.202216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>86</td>\n",
       "      <td>75</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.496988</td>\n",
       "      <td>0.410726</td>\n",
       "      <td>0.447164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.519470</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.204986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>86</td>\n",
       "      <td>76</td>\n",
       "      <td>0.511494</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.427711</td>\n",
       "      <td>0.301068</td>\n",
       "      <td>0.392134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.671500</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.207756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>86</td>\n",
       "      <td>77</td>\n",
       "      <td>0.442529</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.364458</td>\n",
       "      <td>0.285372</td>\n",
       "      <td>0.364450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.527132</td>\n",
       "      <td>0.784176</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>86</td>\n",
       "      <td>78</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.433735</td>\n",
       "      <td>0.558535</td>\n",
       "      <td>0.465901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.593897</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.213296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle  setting1  setting2  setting3   s1        s2        s3        s4  \\\n",
       "0  86     69  0.591954  0.333333       0.0  0.0  0.439759  0.450621  0.380655   \n",
       "1  86     70  0.356322  0.333333       0.0  0.0  0.472892  0.496621  0.293889   \n",
       "2  86     71  0.609195  0.500000       0.0  0.0  0.496988  0.348812  0.447670   \n",
       "3  86     72  0.454023  0.666667       0.0  0.0  0.289157  0.306736  0.451047   \n",
       "4  86     73  0.620690  0.166667       0.0  0.0  0.409639  0.418574  0.362762   \n",
       "5  86     74  0.666667  0.833333       0.0  0.0  0.484940  0.296926  0.294227   \n",
       "6  86     75  0.620690  0.833333       0.0  0.0  0.496988  0.410726  0.447164   \n",
       "7  86     76  0.511494  0.416667       0.0  0.0  0.427711  0.301068  0.392134   \n",
       "8  86     77  0.442529  0.583333       0.0  0.0  0.364458  0.285372  0.364450   \n",
       "9  86     78  0.459770  0.583333       0.0  0.0  0.433735  0.558535  0.465901   \n",
       "\n",
       "    s5     ...      s16       s17  s18  s19       s20       s21  RUL  label1  \\\n",
       "0  0.0     ...      0.0  0.500000  0.0  0.0  0.465116  0.567109  209       0   \n",
       "1  0.0     ...      0.0  0.333333  0.0  0.0  0.666667  0.536868  208       0   \n",
       "2  0.0     ...      0.0  0.416667  0.0  0.0  0.457364  0.624827  207       0   \n",
       "3  0.0     ...      0.0  0.416667  0.0  0.0  0.550388  0.579674  206       0   \n",
       "4  0.0     ...      0.0  0.250000  0.0  0.0  0.612403  0.615576  205       0   \n",
       "5  0.0     ...      0.0  0.500000  0.0  0.0  0.651163  0.579950  204       0   \n",
       "6  0.0     ...      0.0  0.416667  0.0  0.0  0.573643  0.519470  203       0   \n",
       "7  0.0     ...      0.0  0.500000  0.0  0.0  0.604651  0.671500  202       0   \n",
       "8  0.0     ...      0.0  0.333333  0.0  0.0  0.527132  0.784176  201       0   \n",
       "9  0.0     ...      0.0  0.416667  0.0  0.0  0.534884  0.593897  200       0   \n",
       "\n",
       "   label2  cycle_norm  \n",
       "0       0    0.188366  \n",
       "1       0    0.191136  \n",
       "2       0    0.193906  \n",
       "3       0    0.196676  \n",
       "4       0    0.199446  \n",
       "5       0    0.202216  \n",
       "6       0    0.204986  \n",
       "7       0    0.207756  \n",
       "8       0    0.210526  \n",
       "9       0    0.213296  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the previous created final dataset into the workspace\n",
    "# create a local path where we store results\n",
    "if not os.path.exists(TRAIN_DATA):\n",
    "    os.makedirs(TRAIN_DATA)\n",
    "    print('DONE creating a local directory!')\n",
    "\n",
    "# download the entire parquet result folder to local path for a new run \n",
    "for blob in az_blob_service.list_blobs(CONTAINER_NAME):\n",
    "    if TRAIN_DATA in blob.name:\n",
    "        local_file = os.path.join(TRAIN_DATA, os.path.basename(blob.name))\n",
    "        az_blob_service.get_blob_to_path(CONTAINER_NAME, blob.name, local_file)\n",
    "        \n",
    "# load the previous created final dataset into the workspace\n",
    "# create a local path where we store results\n",
    "if not os.path.exists(TRAIN_DATA):\n",
    "    os.makedirs(TRAIN_DATA)\n",
    "    print('DONE creating a local directory!')\n",
    "\n",
    "# download the entire parquet result folder to local path for a new run \n",
    "for blob in az_blob_service.list_blobs(CONTAINER_NAME):\n",
    "    if TRAIN_DATA in blob.name:\n",
    "        local_file = os.path.join(TRAIN_DATA, os.path.basename(blob.name))\n",
    "        az_blob_service.get_blob_to_path(CONTAINER_NAME, blob.name, local_file)\n",
    "\n",
    "train_df = spark.read.parquet(TRAIN_DATA)\n",
    "train_df = train_df.toPandas()\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE creating a local directory!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>RUL</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>cycle_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86</td>\n",
       "      <td>69</td>\n",
       "      <td>0.591954</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.439759</td>\n",
       "      <td>0.450621</td>\n",
       "      <td>0.380655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.567109</td>\n",
       "      <td>209</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.188366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86</td>\n",
       "      <td>70</td>\n",
       "      <td>0.356322</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472892</td>\n",
       "      <td>0.496621</td>\n",
       "      <td>0.293889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.536868</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.191136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "      <td>71</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.496988</td>\n",
       "      <td>0.348812</td>\n",
       "      <td>0.447670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.457364</td>\n",
       "      <td>0.624827</td>\n",
       "      <td>207</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.193906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>72</td>\n",
       "      <td>0.454023</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.289157</td>\n",
       "      <td>0.306736</td>\n",
       "      <td>0.451047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550388</td>\n",
       "      <td>0.579674</td>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.196676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>73</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.409639</td>\n",
       "      <td>0.418574</td>\n",
       "      <td>0.362762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.612403</td>\n",
       "      <td>0.615576</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.199446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>86</td>\n",
       "      <td>74</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484940</td>\n",
       "      <td>0.296926</td>\n",
       "      <td>0.294227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.579950</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.202216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>86</td>\n",
       "      <td>75</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.496988</td>\n",
       "      <td>0.410726</td>\n",
       "      <td>0.447164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.519470</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.204986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>86</td>\n",
       "      <td>76</td>\n",
       "      <td>0.511494</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.427711</td>\n",
       "      <td>0.301068</td>\n",
       "      <td>0.392134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.671500</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.207756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>86</td>\n",
       "      <td>77</td>\n",
       "      <td>0.442529</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.364458</td>\n",
       "      <td>0.285372</td>\n",
       "      <td>0.364450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.527132</td>\n",
       "      <td>0.784176</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>86</td>\n",
       "      <td>78</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.433735</td>\n",
       "      <td>0.558535</td>\n",
       "      <td>0.465901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.593897</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.213296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle  setting1  setting2  setting3   s1        s2        s3        s4  \\\n",
       "0  86     69  0.591954  0.333333       0.0  0.0  0.439759  0.450621  0.380655   \n",
       "1  86     70  0.356322  0.333333       0.0  0.0  0.472892  0.496621  0.293889   \n",
       "2  86     71  0.609195  0.500000       0.0  0.0  0.496988  0.348812  0.447670   \n",
       "3  86     72  0.454023  0.666667       0.0  0.0  0.289157  0.306736  0.451047   \n",
       "4  86     73  0.620690  0.166667       0.0  0.0  0.409639  0.418574  0.362762   \n",
       "5  86     74  0.666667  0.833333       0.0  0.0  0.484940  0.296926  0.294227   \n",
       "6  86     75  0.620690  0.833333       0.0  0.0  0.496988  0.410726  0.447164   \n",
       "7  86     76  0.511494  0.416667       0.0  0.0  0.427711  0.301068  0.392134   \n",
       "8  86     77  0.442529  0.583333       0.0  0.0  0.364458  0.285372  0.364450   \n",
       "9  86     78  0.459770  0.583333       0.0  0.0  0.433735  0.558535  0.465901   \n",
       "\n",
       "    s5     ...      s16       s17  s18  s19       s20       s21  RUL  label1  \\\n",
       "0  0.0     ...      0.0  0.500000  0.0  0.0  0.465116  0.567109  209       0   \n",
       "1  0.0     ...      0.0  0.333333  0.0  0.0  0.666667  0.536868  208       0   \n",
       "2  0.0     ...      0.0  0.416667  0.0  0.0  0.457364  0.624827  207       0   \n",
       "3  0.0     ...      0.0  0.416667  0.0  0.0  0.550388  0.579674  206       0   \n",
       "4  0.0     ...      0.0  0.250000  0.0  0.0  0.612403  0.615576  205       0   \n",
       "5  0.0     ...      0.0  0.500000  0.0  0.0  0.651163  0.579950  204       0   \n",
       "6  0.0     ...      0.0  0.416667  0.0  0.0  0.573643  0.519470  203       0   \n",
       "7  0.0     ...      0.0  0.500000  0.0  0.0  0.604651  0.671500  202       0   \n",
       "8  0.0     ...      0.0  0.333333  0.0  0.0  0.527132  0.784176  201       0   \n",
       "9  0.0     ...      0.0  0.416667  0.0  0.0  0.534884  0.593897  200       0   \n",
       "\n",
       "   label2  cycle_norm  \n",
       "0       0    0.188366  \n",
       "1       0    0.191136  \n",
       "2       0    0.193906  \n",
       "3       0    0.196676  \n",
       "4       0    0.199446  \n",
       "5       0    0.202216  \n",
       "6       0    0.204986  \n",
       "7       0    0.207756  \n",
       "8       0    0.210526  \n",
       "9       0    0.213296  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the previous created final dataset into the workspace\n",
    "# create a local path where we store results\n",
    "if not os.path.exists(TEST_DATA):\n",
    "    os.makedirs(TEST_DATA)\n",
    "    print('DONE creating a local directory!')\n",
    "\n",
    "# download the entire parquet result folder to local path for a new run \n",
    "for blob in az_blob_service.list_blobs(CONTAINER_NAME):\n",
    "    if TRAIN_DATA in blob.name:\n",
    "        local_file = os.path.join(TEST_DATA, os.path.basename(blob.name))\n",
    "        az_blob_service.get_blob_to_path(CONTAINER_NAME, blob.name, local_file)\n",
    "        \n",
    "# load the previous created final dataset into the workspace\n",
    "# create a local path where we store results\n",
    "if not os.path.exists(TEST_DATA):\n",
    "    os.makedirs(TEST_DATA)\n",
    "    print('DONE creating a local directory!')\n",
    "\n",
    "# download the entire parquet result folder to local path for a new run \n",
    "for blob in az_blob_service.list_blobs(CONTAINER_NAME):\n",
    "    if TEST_DATA in blob.name:\n",
    "        local_file = os.path.join(TEST_DATA, os.path.basename(blob.name))\n",
    "        az_blob_service.get_blob_to_path(CONTAINER_NAME, blob.name, local_file)\n",
    "\n",
    "test_df = spark.read.parquet(TRAIN_DATA)\n",
    "test_df = test_df.toPandas()\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "\n",
    "The traditional predictive maintenance machine learning models are based on feature engineering which is manual construction of right features using domain expertise and similar methods. This usually makes these models hard to reuse since feature engineering is specific to the problem scenario and the available data which varies from one business to the other. Perhaps the most attractive part of applying deep learning in the predictive maintenance domain is the fact that these networks can automatically extract the right features from the data, eliminating the need for manual feature engineering.\n",
    "\n",
    "When using LSTMs in the time-series domain, one important parameter to pick is the sequence length which is the window for LSTMs to look back. This may be viewed as similar to picking window_size = 5 cycles for calculating the rolling features in the [Predictive Maintenance Template](https://gallery.cortanaintelligence.com/Collection/Predictive-Maintenance-Template-3) which are rolling mean and rolling standard deviation for 21 sensor values. The idea of using LSTMs is to let the model extract abstract features out of the sequence of sensor values in the window rather than engineering those manually. The expectation is that if there is a pattern in these sensor values within the window prior to failure, the pattern should be encoded by the LSTM.\n",
    "\n",
    "One critical advantage of LSTMs is their ability to remember from long-term sequences (window sizes) which is hard to achieve by traditional feature engineering. For example, computing rolling averages over a window size of 50 cycles may lead to loss of information due to smoothing and abstracting of values over such a long period, istead, using all 50 values as input may provide better results. While feature engineering over large window sizes may not make sense, LSTMs are able to use larger window sizes and use all the information in the window as input. Below, we illustrate the approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a large window size of 50 cycles\n",
    "sequence_length = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Keras LSTM](https://keras.io/layers/recurrent/) layers expect an input in the shape of a numpy array of 3 dimensions (samples, time steps, features) where samples is the number of training sequences, time steps is the look back window or sequence length and features is the number of features of each sequence at each time step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to reshape features into (samples, time steps, features) \n",
    "def gen_sequence(id_df, seq_length, seq_cols):\n",
    "    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n",
    "    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n",
    "    we can use shorter ones \"\"\"\n",
    "    data_array = id_df[seq_cols].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
    "        yield data_array[start:stop, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the feature columns \n",
    "sensor_cols = ['s' + str(i) for i in range(1,22)]\n",
    "sequence_cols = ['setting1', 'setting2', 'setting3', 'cycle_norm']\n",
    "input_features = sensor_cols + sequence_cols\n",
    "input_features\n",
    "sequence_cols.extend(sensor_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator for the sequences\n",
    "seq_gen = (list(gen_sequence(train_df[test_df['id']==id], sequence_length, sequence_cols)) \n",
    "           for id in train_df['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15631, 50, 25)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate sequences and convert to numpy array\n",
    "seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
    "seq_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate labels\n",
    "def gen_labels(id_df, seq_length, label):\n",
    "    data_array = id_df[label].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    return data_array[seq_length:num_elements, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15631, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate labels\n",
    "label_gen = [gen_labels(train_df[train_df['id']==id], sequence_length, ['label1']) \n",
    "             for id in train_df['id'].unique()]\n",
    "label_array = np.concatenate(label_gen).astype(np.float32)\n",
    "label_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Network\n",
    "Next, we build a deep network. The first layer is an LSTM layer with 100 units followed by another LSTM layer with 50 units. Dropout is also applied after each LSTM layer to control overfitting. Final layer is a Dense output layer with single unit and sigmoid activation since this is a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the network\n",
    "nb_features = seq_array.shape[2]\n",
    "nb_out = label_array.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(\n",
    "         input_shape=(sequence_length, nb_features),\n",
    "         units=100,\n",
    "         return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(\n",
    "          units=50,\n",
    "          return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=nb_out, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 50, 100)           50400     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 80,651\n",
      "Trainable params: 80,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14849 samples, validate on 782 samples\n",
      "Epoch 1/10\n",
      "14849/14849 [==============================] - 11s 747us/step - loss: 0.2657 - acc: 0.8905 - val_loss: 0.1992 - val_acc: 0.9003\n",
      "Epoch 2/10\n",
      "14849/14849 [==============================] - 10s 685us/step - loss: 0.1123 - acc: 0.9547 - val_loss: 0.1093 - val_acc: 0.9450\n",
      "Epoch 3/10\n",
      "14849/14849 [==============================] - 10s 675us/step - loss: 0.0850 - acc: 0.9670 - val_loss: 0.0930 - val_acc: 0.9591\n",
      "Epoch 4/10\n",
      "14849/14849 [==============================] - 10s 691us/step - loss: 0.0722 - acc: 0.9714 - val_loss: 0.1230 - val_acc: 0.9437\n",
      "CPU times: user 3min 13s, sys: 39.9 s, total: 3min 53s\n",
      "Wall time: 42.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9397f01240>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# fit the network\n",
    "model.fit(seq_array, label_array, epochs=10, batch_size=200, validation_split=0.05, verbose=1,\n",
    "          callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15631/15631 [==============================] - 3s 204us/step\n",
      "Accurracy: 0.9579681406612321\n"
     ]
    }
   ],
   "source": [
    "# training metrics\n",
    "scores = model.evaluate(seq_array, label_array, verbose=1, batch_size=200)\n",
    "print('Accurracy: {}'.format(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15631/15631 [==============================] - 3s 209us/step\n",
      "Confusion matrix\n",
      "- x-axis is true labels.\n",
      "- y-axis is predicted labels\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[12546,    49],\n",
       "       [  608,  2428]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions and compute confusion matrix\n",
    "y_pred = model.predict_classes(seq_array,verbose=1, batch_size=200)\n",
    "y_true = label_array\n",
    "print('Confusion matrix\\n- x-axis is true labels.\\n- y-axis is predicted labels')\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision =  0.980218005652 \n",
      " recall =  0.799736495389\n"
     ]
    }
   ],
   "source": [
    "# compute precision and recall\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "print( 'precision = ', precision, '\\n', 'recall = ', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persist the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll save the latest model for use in deploying a webservice for operationalization in the next notebook. We store this local to the Jupyter notebook kernel because the model is stored in a hierarchical format that does not translate to Azure Blob storage well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import h5py\n",
    "from sklearn import datasets \n",
    "\n",
    "# save model\n",
    "model.save(os.environ['AZUREML_NATIVE_SHARE_DIRECTORY']+'pdmrfull.model')\n",
    "#model.save('./outputs/lstm_model.h5py')\n",
    "print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In the next notebook Code\\3_operationalization.ipynb Jupyter notebook we will create the functions needed to operationalize and deploy any model to get realtime predictions."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "lstm DLForPM",
   "language": "python",
   "name": "lstm_dlforpm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
